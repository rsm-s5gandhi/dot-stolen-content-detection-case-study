{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d678ca",
   "metadata": {},
   "source": [
    "# Stolen Content Detection Model\n",
    "\n",
    "In this notebook, I build a simple text-similarity model to detect stolen posts on DOT.\n",
    "\n",
    "Goal:\n",
    "- Use only **post text and timestamps** (no ground-truth labels).\n",
    "- Flag posts that are likely duplicates of earlier posts.\n",
    "- Compare model predictions to our synthetic ground truth (`is_stolen`) to see how well a real-world detector could perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8b7719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/sakshigandhi/Desktop/dot_stolen_content_project/.venv/lib/python3.14/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/sakshigandhi/Desktop/dot_stolen_content_project/.venv/lib/python3.14/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/sakshigandhi/Desktop/dot_stolen_content_project/.venv/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/sakshigandhi/Desktop/dot_stolen_content_project/.venv/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/sakshigandhi/Desktop/dot_stolen_content_project/.venv/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59d0c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04f9f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>is_original</th>\n",
       "      <th>is_stolen</th>\n",
       "      <th>created_at</th>\n",
       "      <th>media_type</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>share_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>image</td>\n",
       "      <td>Content group 1 original post about topic 9</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>image</td>\n",
       "      <td>Content group 2 original post about topic 18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1170</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>video</td>\n",
       "      <td>Content group 3 original post about topic 23</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>video</td>\n",
       "      <td>Content group 4 original post about topic 34</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2024-07-05</td>\n",
       "      <td>video</td>\n",
       "      <td>Content group 5 original post about topic 4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  author_id  group_id  is_original  is_stolen  created_at  \\\n",
       "0        1       2986         1         True      False  2024-08-04   \n",
       "1        2        559         2         True      False  2024-07-17   \n",
       "2        3       1170         3         True      False  2024-07-24   \n",
       "3        4         21         4         True      False  2024-07-26   \n",
       "4        5        130         5         True      False  2024-07-05   \n",
       "\n",
       "  media_type                                          text  like_count  \\\n",
       "0      image   Content group 1 original post about topic 9          37   \n",
       "1      image  Content group 2 original post about topic 18           2   \n",
       "2      video  Content group 3 original post about topic 23          28   \n",
       "3      video  Content group 4 original post about topic 34          20   \n",
       "4      video   Content group 5 original post about topic 4           9   \n",
       "\n",
       "   comment_count  share_count  \n",
       "0              9            1  \n",
       "1              0            0  \n",
       "2              4            2  \n",
       "3              4            2  \n",
       "4              1            0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load posts table generated in step 1\n",
    "posts = pd.read_csv(\"../data/posts.csv\")\n",
    "users = pd.read_csv(\"../data/users.csv\")\n",
    "impr = pd.read_csv(\"../data/feed_impressions.csv\")\n",
    "\n",
    "posts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2566b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3021, 11), (3000, 5))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape, users.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53a9ab",
   "metadata": {},
   "source": [
    "## Text preprocessing and vectorization\n",
    "\n",
    "Here I:\n",
    "1. Clean the post text (lowercase, fill missing).\n",
    "2. Use TF-IDF to turn each post into a text vector.\n",
    "3. This lets me compute cosine similarity between posts to detect near-duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69d38948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3021, 1454)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic text cleaning\n",
    "posts[\"text\"] = posts[\"text\"].fillna(\"\").astype(str)\n",
    "posts[\"post_text_clean\"] = posts[\"text\"].str.lower()\n",
    "\n",
    "# TF-IDF vectorization on unigrams and bigrams\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(posts[\"post_text_clean\"])\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8493e8",
   "metadata": {},
   "source": [
    "## Similarity graph between posts\n",
    "\n",
    "Next, I compute cosine similarity between every pair of posts.\n",
    "For each post, I find the **most similar other post** and treat that as its best candidate \"original\".\n",
    "\n",
    "Later, if:\n",
    "- similarity is high, and  \n",
    "- the candidate original is **older**\n",
    "\n",
    "then I flag the newer post as a potential stolen post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "127b15ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>best_match_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.744558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.746047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  best_match_score\n",
       "0        1          1.000000\n",
       "1        2          0.744558\n",
       "2        3          1.000000\n",
       "3        4          0.746047\n",
       "4        5          1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cosine similarity between all posts (works fine for ~3k posts)\n",
    "sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# A post is perfectly similar to itself; set diagonal to 0\n",
    "np.fill_diagonal(sim_matrix, 0)\n",
    "\n",
    "# For each post, find the index of the most similar other post\n",
    "best_match_idx = sim_matrix.argmax(axis=1)\n",
    "best_match_score = sim_matrix.max(axis=1)\n",
    "\n",
    "posts[\"best_match_index\"] = best_match_idx\n",
    "posts[\"best_match_score\"] = best_match_score\n",
    "\n",
    "posts[[\"post_id\", \"best_match_score\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1072f3",
   "metadata": {},
   "source": [
    "## Rule-based detector: is this post stolen?\n",
    "\n",
    "Heuristic:\n",
    "- If a post's best match has cosine similarity above a threshold (e.g. 0.8)\n",
    "- and the best-match post was created **earlier in time**\n",
    "- then the newer post is flagged as `pred_is_stolen = True`.\n",
    "\n",
    "This simulates how a simple production detector might work using only text similarity and time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbc2c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_is_stolen\n",
       "False    1912\n",
       "True     1109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure created_at is in datetime format\n",
    "posts[\"created_at\"] = pd.to_datetime(posts[\"created_at\"])\n",
    "\n",
    "# Get numpy arrays for speed\n",
    "created_at_values = posts[\"created_at\"].values\n",
    "best_match_created_at = created_at_values[best_match_idx]\n",
    "\n",
    "# Similarity threshold\n",
    "SIM_THRESHOLD = 0.8\n",
    "\n",
    "posts[\"pred_is_stolen\"] = (\n",
    "    (posts[\"best_match_score\"] >= SIM_THRESHOLD) &\n",
    "    (created_at_values > best_match_created_at)   # newer than its best match\n",
    ")\n",
    "\n",
    "posts[[\"post_id\", \"best_match_score\", \"pred_is_stolen\"]].head()\n",
    "posts[\"pred_is_stolen\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeace86",
   "metadata": {},
   "source": [
    "## Model evaluation against synthetic ground truth\n",
    "\n",
    "Because I generated the dataset, I have a true `is_stolen` label for each post.\n",
    "\n",
    "I can now:\n",
    "- Compare my rule-based detector (`pred_is_stolen`) with `is_stolen`\n",
    "- Compute precision, recall, F1-score\n",
    "- Look at the confusion matrix to see where the model makes mistakes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a74cfa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance (true):\n",
      "is_stolen\n",
      "False    0.662032\n",
      "True     0.337968\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      0.640     0.612     0.625      2000\n",
      "        True      0.299     0.325     0.312      1021\n",
      "\n",
      "    accuracy                          0.515      3021\n",
      "   macro avg      0.470     0.468     0.468      3021\n",
      "weighted avg      0.525     0.515     0.519      3021\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[1223  777]\n",
      " [ 689  332]]\n"
     ]
    }
   ],
   "source": [
    "# Ground truth label from our generator\n",
    "y_true = posts[\"is_stolen\"].astype(bool)\n",
    "y_pred = posts[\"pred_is_stolen\"].astype(bool)\n",
    "\n",
    "print(\"Class balance (true):\")\n",
    "print(y_true.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4f0a6",
   "metadata": {},
   "source": [
    "## Who does the detector protect (or fail)?\n",
    "\n",
    "Finally, I segment model performance by creator type and geography to see:\n",
    "\n",
    "- Are we better at catching stolen content for some creators than others?\n",
    "- Do we under-protect certain countries or segments?\n",
    "\n",
    "This is important for fairness and long-term ecosystem health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b032ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kx/5c3b5w651_ngzv1nq36smyxc0000gn/T/ipykernel_90872/1266911861.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_posts</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>0.297436</td>\n",
       "      <td>0.310992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>765.0</td>\n",
       "      <td>0.320690</td>\n",
       "      <td>0.341912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>463.0</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>443.0</td>\n",
       "      <td>0.266272</td>\n",
       "      <td>0.304054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>255.0</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_posts  precision    recall\n",
       "country                              \n",
       "US        1095.0   0.297436  0.310992\n",
       "IN         765.0   0.320690  0.341912\n",
       "BR         463.0   0.305882  0.351351\n",
       "GB         443.0   0.266272  0.304054\n",
       "CA         255.0   0.288889  0.325000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load users to join creator attributes\n",
    "users = pd.read_csv(\"../data/users.csv\")\n",
    "\n",
    "posts_with_users = posts.merge(\n",
    "    users,\n",
    "    left_on=\"author_id\",\n",
    "    right_on=\"user_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_user\")\n",
    ")\n",
    "\n",
    "# Example: performance by country\n",
    "country_stats = (\n",
    "    posts_with_users\n",
    "    .groupby(\"country\")\n",
    "    .apply(lambda df: pd.Series({\n",
    "        \"n_posts\": len(df),\n",
    "        \"precision\": (\n",
    "            (df[\"pred_is_stolen\"] & df[\"is_stolen\"]).sum() /\n",
    "            max(df[\"pred_is_stolen\"].sum(), 1)\n",
    "        ),\n",
    "        \"recall\": (\n",
    "            (df[\"pred_is_stolen\"] & df[\"is_stolen\"]).sum() /\n",
    "            max(df[\"is_stolen\"].sum(), 1)\n",
    "        )\n",
    "    }))\n",
    "    .sort_values(\"n_posts\", ascending=False)\n",
    ")\n",
    "\n",
    "country_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae253d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this step, I built a simple text similarityâ€“based detector for stolen posts on DOT:\n",
    "\n",
    "- Represented posts using **TF-IDF** over unigrams and bigrams.\n",
    "- Computed **cosine similarity** between all posts to find the best candidate original for each post.\n",
    "- Used a rule-based heuristic (similarity threshold + earlier timestamp) to flag potential stolen posts.\n",
    "- Evaluated the detector against synthetic ground truth (`is_stolen`) and reported precision/recall/F1.\n",
    "- Segmented performance by **country** (and optionally creator type) to understand fairness and coverage.\n",
    "\n",
    "This mirrors how a Data Scientist in a product analytics role might:\n",
    "- Prototype a detection signal\n",
    "- Quantify its quality\n",
    "- And connect model performance back to **creator experience** and **ecosystem health**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "72d27fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv(\"../data/posts_with_predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
